{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7479</td>\n",
       "      <td>-0.886751</td>\n",
       "      <td>-0.373192</td>\n",
       "      <td>1.104696</td>\n",
       "      <td>1.232271</td>\n",
       "      <td>-0.891560</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.187705</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3411</td>\n",
       "      <td>0.608663</td>\n",
       "      <td>-0.183385</td>\n",
       "      <td>1.104696</td>\n",
       "      <td>0.600563</td>\n",
       "      <td>-0.891560</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.333945</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6027</td>\n",
       "      <td>2.052152</td>\n",
       "      <td>0.480939</td>\n",
       "      <td>-0.503694</td>\n",
       "      <td>1.027098</td>\n",
       "      <td>0.830152</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.503095</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1247</td>\n",
       "      <td>-1.457915</td>\n",
       "      <td>-1.417129</td>\n",
       "      <td>0.461340</td>\n",
       "      <td>-1.233163</td>\n",
       "      <td>0.830152</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.071061</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3716</td>\n",
       "      <td>0.130961</td>\n",
       "      <td>-1.132419</td>\n",
       "      <td>-0.825373</td>\n",
       "      <td>1.140475</td>\n",
       "      <td>-0.891560</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.524268</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore       Age    Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "7479    -0.886751 -0.373192  1.104696  1.232271      -0.891560          1   \n",
       "3411     0.608663 -0.183385  1.104696  0.600563      -0.891560          0   \n",
       "6027     2.052152  0.480939 -0.503694  1.027098       0.830152          0   \n",
       "1247    -1.457915 -1.417129  0.461340 -1.233163       0.830152          1   \n",
       "3716     0.130961 -1.132419 -0.825373  1.140475      -0.891560          0   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
       "7479               0        -0.187705                  0                1   \n",
       "3411               0        -0.333945                  0                0   \n",
       "6027               1         1.503095                  1                0   \n",
       "1247               0        -1.071061                  0                0   \n",
       "3716               0         1.524268                  1                0   \n",
       "\n",
       "      Gender_Male  \n",
       "7479            1  \n",
       "3411            0  \n",
       "6027            1  \n",
       "1247            1  \n",
       "3716            0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "data = pd.read_csv('/datasets/Churn.csv',  sep=',')\n",
    "\n",
    "# Предобработка\n",
    "data = data.drop(['RowNumber','CustomerId','Surname'], axis=1) #удалим ненужные столбцы\n",
    "data = pd.get_dummies(data, drop_first=True) # получение дамми-признаков\n",
    "data['Tenure'][data['Tenure'].isnull()]=0 # заменим пропуски \n",
    "data['Tenure']=data['Tenure'].astype(int)\n",
    "\n",
    "# Деление данных\n",
    "data_train, data_valid = train_test_split(data, test_size=0.40, random_state=12345)\n",
    "data_test, data_valid = train_test_split(data_valid, test_size=0.50, random_state=12345)\n",
    "features_train = data_train.drop(['Exited'], axis=1)\n",
    "target_train = data_train['Exited']\n",
    "features_valid = data_valid.drop(['Exited'], axis=1)\n",
    "target_valid = data_valid['Exited']\n",
    "features_test = data_test.drop(['Exited'], axis=1)\n",
    "target_test = data_test['Exited']\n",
    "# Маштабирование\n",
    "numeric = ['CreditScore', 'Age', 'Tenure', 'Balance','NumOfProducts','EstimatedSalary']\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "features_test[numeric] = scaler.transform(features_test[numeric])\n",
    "\n",
    "features_train.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод\n",
    " - В таблице присутствуют бесполезные для модели столбцы (индекс строки в данных, уникальный идентификатор клиента, фамилия) удалим их.\n",
    " - Разделим категориальные признаки (Страна,Пол) с помощью One-hot-encoding.\n",
    " - В столбце - 'количество недвижимости', отсутствует часть данных. Заполним пропуски. \n",
    " - разделим данные на три выборки.\n",
    " - отмасштабируем столбцы с небинарными данными.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Исследование задачи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Баланс классов\n",
      "0    0.7963\n",
      "1    0.2037\n",
      "Name: Exited, dtype: float64\n",
      "Значение F1-меры 0.2743055555555555\n"
     ]
    }
   ],
   "source": [
    "# Исследование баланса классов\n",
    "class_frequency = data['Exited'].value_counts(normalize=True)\n",
    "print('Баланс классов')\n",
    "print(class_frequency)\n",
    "class_frequency.plot(kind='bar')\n",
    "\n",
    "# Обучение модели без учёта дисбаланса\n",
    "model = LogisticRegression(random_state=12345,solver='liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print('Значение F1-меры',f1_score(target_valid,predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Исследование баланса классов\n",
    " - Наблюдается дисбаланс положительного класса в целевом признаке 'Exited'. отрицательных признаков в пять раз больше.\n",
    " \n",
    "#### Обучение модели без учёта дисбаланса\n",
    " - применим метод логистической регрессии для проверки модели обученной на несбалансированных данных.\n",
    " - Значение F1-меры - 0.27. Слишком низко. Необходима борьба с дисбалансом.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Борьба с дисбалансом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Взвешивание классов\n",
      "Лог. регрессия F1 valid: 0.4797238999137188\n",
      "Лог. регрессия train F1: 0.5\n",
      "Лог. регрессия valid auc_roc 0.7417876058170719\n",
      "\n",
      "Увеличение выборки\n",
      "Лог. регрессия valid F1: 0.486610558530987\n",
      "Лог. регрессия train F1: 0.4796238244514106\n",
      "Лог. регрессия valid auc_roc 0.7420004767108749\n",
      "\n",
      "Уменьшение выборки\n",
      "Лог. регрессия valid F1: 0.4305239179954442\n",
      "Лог. регрессия train F1: 0.42554858934169276\n",
      "Лог. регрессия valid auc_roc 0.7358631989698248\n"
     ]
    }
   ],
   "source": [
    "# Взвешивание классов\n",
    "model2 = LogisticRegression(random_state=12345, solver='liblinear',class_weight='balanced')\n",
    "model2.fit(features_train, target_train)\n",
    "predicted_valid2 = model2.predict(features_valid)\n",
    "predicted_train2 = model2.predict(features_train)\n",
    "probabilities_one_valid2 = model2.predict_proba(features_valid)[:, 1]\n",
    "print('Взвешивание классов')\n",
    "print(\"Лог. регрессия F1 valid:\",f1_score(target_valid,predicted_valid2))\n",
    "print(\"Лог. регрессия train F1:\", f1_score(target_train, predicted_train2))\n",
    "print('Лог. регрессия valid auc_roc',roc_auc_score(target_valid, probabilities_one_valid2))\n",
    "\n",
    "\n",
    "# Увеличение выборки\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345)\n",
    "    \n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 5)\n",
    "\n",
    "print()\n",
    "print('Увеличение выборки')\n",
    "# Логистическая регрессия\n",
    "\n",
    "model3 = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model3.fit(features_upsampled, target_upsampled)\n",
    "predicted_valid3 = model3.predict(features_valid)\n",
    "predicted_train3 = model3.predict(features_train)\n",
    "probabilities_one_valid2 = model3.predict_proba(features_valid)[:, 1]\n",
    "print(\"Лог. регрессия valid F1:\", f1_score(target_valid, predicted_valid3))\n",
    "print(\"Лог. регрессия train F1:\", f1_score(target_train, predicted_train3))\n",
    "print('Лог. регрессия valid auc_roc',roc_auc_score(target_valid, probabilities_one_valid2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Уменьшение выборки\n",
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "    \n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=12345)\n",
    "    \n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "features_downsampled, target_downsampled = downsample(features_train, target_train, 0.1)\n",
    "\n",
    "print()\n",
    "print('Уменьшение выборки')\n",
    "# Логистическая регрессия\n",
    "model3 = LogisticRegression(random_state=12345,solver='liblinear')\n",
    "model3.fit(features_downsampled, target_downsampled)\n",
    "predicted_valid3 = model3.predict(features_valid)\n",
    "predicted_train3 = model3.predict(features_train)\n",
    "probabilities_one_valid2 = model3.predict_proba(features_valid)[:, 1]\n",
    "print(\"Лог. регрессия valid F1:\", f1_score(target_valid, predicted_valid3))\n",
    "print(\"Лог. регрессия train F1:\", f1_score(target_train, predicted_train3))\n",
    "print('Лог. регрессия valid auc_roc',roc_auc_score(target_valid, probabilities_one_valid2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод\n",
    "В борьбе с дисбалансом увеличение выборки показало лучший результат по всем параметрам, чем взвешивание классов по регрессионной модели. Попробуем увеличение выборки для моделей с деревьями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max F1 Дерево решений\n",
      "валидационная выборка: 0.55 ; auc_roc: 0.83 ; тренировочная выборка: 0.54 ; max_depth =  5\n",
      "Max F1 Случайный лес\n",
      "валидационная выборка:0.61 ; auc_roc: 0.84 ; тренировочная выборка:0.71 ; max_depth =  9 ; n_estimators =  19\n"
     ]
    }
   ],
   "source": [
    "# Классификация деревом решений, Увеличенная выбока:\n",
    "F1=0\n",
    "F11=0\n",
    "max_depth1=1\n",
    "for estim in range(1, 30):\n",
    "    model4 = DecisionTreeClassifier(random_state=12345, max_depth=estim)\n",
    "    model4.fit(features_upsampled, target_upsampled)\n",
    "    predicted_valid4 = model4.predict(features_valid)\n",
    "    predicted_train4 = model4.predict(features_train)\n",
    "    if F1 <= f1_score(target_valid, predicted_valid4):\n",
    "            F1 = f1_score(target_valid, predicted_valid4)\n",
    "            F11 = f1_score(target_train, predicted_train4)\n",
    "            max_depth1 = estim\n",
    "            probabilities_one_valid4 = model4.predict_proba(features_valid)[:, 1]\n",
    "print(\"Max F1 Дерево решений\")\n",
    "print(\"валидационная выборка: {:.2f}\".format(F1),end=\" ; \")\n",
    "print('auc_roc: {:.2f}'.format(roc_auc_score(target_valid, probabilities_one_valid4)),end=\" ; \")\n",
    "print(\"тренировочная выборка: {:.2f}\".format(F11),end=\" ; \")\n",
    "print(\"max_depth = \", max_depth1)\n",
    "\n",
    "# Классификация случайным лесом, Увеличенная выбока:\n",
    "valid=0\n",
    "train=1\n",
    "max_depth=1\n",
    "n_estimators=1\n",
    "for i in range(1,20):\n",
    "    for estim in range(1, 10):\n",
    "        model = RandomForestClassifier(random_state=12345, n_estimators=i, max_depth=estim)# создать модель\n",
    "        model.fit(features_upsampled, target_upsampled)# обучить модель\n",
    "        predicted_valid = model.predict(features_valid)\n",
    "        predicted_train = model.predict(features_train)\n",
    "        if valid < f1_score(predicted_valid, target_valid) or train > f1_score(predicted_train, target_train):\n",
    "            valid = f1_score(predicted_valid, target_valid)\n",
    "            train = f1_score(predicted_train, target_train)\n",
    "            model5=model\n",
    "            max_depth = estim\n",
    "            n_estimators = i\n",
    "            probabilities_one_valid5 = model5.predict_proba(features_valid)[:, 1]\n",
    "\n",
    "print('Max F1 Случайный лес')        \n",
    "print(\"валидационная выборка:{:.2f}\".format(valid),end=\" ; \")\n",
    "print('auc_roc: {:.2f}'.format(roc_auc_score(target_valid, probabilities_one_valid5)),end=\" ; \")\n",
    "print(\"тренировочная выборка:{:.2f}\".format(train),end=\" ; \")\n",
    "print(\"max_depth = \", max_depth,end=\" ; \")\n",
    "print(\"n_estimators = \", n_estimators)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод\n",
    " - Для Увеличенной выборки модель случайного леса показала намного выше F1=0,61 чем у дерева решений, так же показатель auc_roc 0.84 свидетельствует, что модель является адекватной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Тестирование модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестовая выборка, Случайный лес F1:0.60 ; auc_roc:0.85\n"
     ]
    }
   ],
   "source": [
    "predicted_test = model5.predict(features_test)\n",
    "probabilities_one_test = model5.predict_proba(features_test)[:, 1]\n",
    "print(\"Тестовая выборка, Случайный лес F1:{:.2f}\".format(f1_score(target_test, predicted_test)),end=\" ; \")\n",
    "print('auc_roc:{:.2f}'.format(roc_auc_score(target_test, probabilities_one_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод\n",
    "- Тестирование лучшей модели случайного леса дало приемлемые результаты: F1 мера -0,6.  auc_roc для тестовой выборки -0.85. Модель адекватная."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
